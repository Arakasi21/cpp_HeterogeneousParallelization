Ответы на Контрольные вопросы к Assignment 2

Ответы на контрольные вопросы
1. Что понимается под гетерогенной параллелизацией?
Гетерогенная параллелизация - это использование различных типов процессоров для выполнения одной задачи. В основном это комбинация CPU и GPU, где CPU управляет последовательными частями программы и сложной логикой, а GPU обрабатывает массивные параллельные вычисления. Каждый процессор выполняет ту часть работы, для которой он лучше приспособлен архитектурно

2. В чём принципиальные различия архитектур CPU и GPU?

CPU содержит небольшое количество мощных ядер , каждое из которых может выполнять сложные операции независимо. Архитектура оптимизирована для последовательных задач с множеством ветвлений и сложной логикой.

GPU состоит из тысяч простых вычислительных ядер, организованных по архитектуре SIMT (Single Instruction Multiple Threads). Все потоки выполняют одну инструкцию, но на разных данных. GPU имеет иерархию памяти: global memory (большая но медленная), shared memory (быстрая но ограниченная размером), регистры (самые быстрые)

Основное отличие: CPU - небольшое количество мощных ядер для сложной логики, GPU - большое количество простых ядер для массовых параллельных вычислений.

3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?
GPU эффективен для:

Обработки больших массивов данных (умножение матриц, операции над векторами)
Задач с высокой степенью параллелизма данных
Вычислений с минимальным ветвлением кода
Обработки изображений, графики, нейронных сетей
Операций, где одна инструкция применяется к миллионам элементов

CPU лучше подходит для:

Алгоритмов со сложными ветвлениями и условной логикой
Последовательных задач с зависимостями между шагами
Работы с файловой системой и базами данных
Задач с малым объемом данных
Управления программой и координации работы GPU

4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?

Основная проблема - наличие зависимостей данных между итерациями. Например, в сортировке выбором каждая итерация зависит от результата предыдущей, что делает полную параллелизацию невозможной.

5. В чём заключается основная идея алгоритма сортировки слиянием?

Разделение: массив рекурсивно делится пополам до получения подмассивов размером 1 элемент
Слияние: отсортированные подмассивы последовательно объединяются попарно в отсортированном порядке

Алгоритм хорошо подходит для параллелизации, так как независимые части массива можно сортировать одновременно и процесс слияния также можно распараллелить

6. Какие сложности возникают при реализации сортировки слиянием на GPU?

Основные проблемы:

Параллелизация слияния - классический алгоритм слияния последовательный. Для эффективной параллельной реализации требуются специальные алгоритмы, где каждый поток может независимо определить свою позицию в результирующем массиве

Синхронизация между блоками - после каждого уровня слияния требуется глобальная синхронизация (cudaDeviceSynchronize()), чтобы гарантировать завершение всех операций

Ограничения shared memory - максимальный размер 48KB на блок ограничивает размер данных для быстрого доступа, для больших слияний приходится использовать медленную global memor

В моей реализации задания 4 эти проблемы привели к тому, что GPU показал ускорение только на массивах от 1 миллиона элементов

7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?

Размер блока (blockSize):

Должен быть кратен размеру warp (32 потока) для эффективного использования SIMT архитектуры
Слишком маленький блок (< 128) - низкая утилизация SM и недостаточное скрытие латентности памяти
Слишком большой блок (> 512) - может снизить occupancy из-за ограничений на регистры и shared memory
Оптимальный размер обычно 256-512 потоков на блок

Размер сетки (gridSize):

Определяет количество блоков и должен быть достаточным для покрытия всех данных
Слишком мало блоков - простаивают SM
Формула: gridSize = (N + blockSize - 1) / blockSize обеспечивает покрытие

В моей реализации blockSize=256 оказался оптимальным балансом между occupancy и использованием ресурсов.

8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?
Гетерогенный подход позволяет использовать сильные стороны каждого типа процессора:
Например, CPU эффективно управляет программой, обрабатывает ветвления и последовательную логику а GPU одновременно обрабатывает массивные параллельные вычисления
Т.е. гарантируется оптимальное распределение нагрузки в зависимости от характера задачи

Эффективность достигается когда выигрыш от параллелизма на GPU превышает затраты на передачу данных и управление.