# cpp_HeterogeneousParallelization

Внутри тасков есть краткий README с результатами.

Основа для изучения https://metanit.com/cpp/tutorial/

Также внутри кода комментарии

Ответы на вопросы:

1. В чём отличие динамического массива от статического массива в языке C++?

-> Статический - сам освобождается

Размер фиксирован при компиляции (константа)
Память в стеке

-> Динамический:

Размер определяется во время выполнения (переменная)
Память в куче

2. Что такое указатель и зачем он используется при работе с динамической памятью?

Указатель - объект в С++, значения в котором служат адреса других объектов или функций  (используются для косвенного доступа к объекту)

тип_данных* название_указателя;

Существуют как глобальные так и локальные объекты. Они оба помещаются в статической памяти (стек). Они создаются и удаляются компилятором. Память, выделяемая для стека, имеет ограниченный фиксированный размер

В свою очередь, динамический объект существует пока не будет удален явным образом. Размещается в динамической памяти (free store)

Для управления динамическими объектами применяются операторы new и delete.

Оператор new выделяет место в динамической памяти для объекта и возвращает указатель на этот объект.

Оператор delete получает указатель на динамический объект и удаляет его из памяти.

3. Почему важно корректно освобождать память после использования динамических
массивов?

Динамический массив хранится в динамической памяти, и удаляется только явным образом.
Динамические объекты будут существовать, пока не будут явным образом удалены. И после завершения использования динамических объектов следует освободить их память с помощью оператора delete:

Также даже после освобождения памяти указатель по-прежнему содержит старый адрес, поэтому рекомендуется после освобождения памяти обнулять указатель

4. В чём разница между последовательной и параллельной обработкой массива?

Операции массива выполняется последовательно, шаг за шагом (по очереди) - некая однопоточность

В свою очередь параллельная обработка массива - многопоточность, когда несколько потоков / ядер работают (выполняют) операции над массивом

5. Что делает директива #pragma omp parallel for?

#pragma omp for -> Обозначает, что итерации следующего за директивой цикла должны быть распределены между потоками. Обычно используется внутри parallel.

В свою очередь #pragma omp parallel директива создает параллельную область: несколько потоков начинают выполнение кода внутри этой области. Каждый поток исполняет одну и ту же копию кода

Директива OpenMP parallel for делит итерации цикла for между несколькими потоками. Каждый поток получает свое значение счетчика i в диапазоне от 0 до 7 (если используем 8 процессоров (7 потоков + 1 основной). В моем случае 4 процессора, где 3 потока и 1 основной)

6. Для чего используется механизм reduction в OpenMP?

Основная цель устранение гонок данных (race conditions) при вычислении, чтобы каждый поток не перезаписывал условное sum значение + эффективная параллелизация

7. Почему при параллельном вычислении суммы необходимо использовать reduction,
а не обычную переменную?

reduction - каждый поток работает со своей локальной переменной. Если мы не укажем reduction(:sum) то может возникнуть случай при котором запись одного потока потеряется, и финальное значение (ответ) может быть опасным

И в конце всех итерации каждый поток суммируется

8. Какие факторы могут привести к тому, что параллельная версия программы будет
работать медленнее последовательной?

В моем случае -> когда изначальное кол-во элементов в массиве мало, и параллелизация будет не эффективной. Также зависимость результата итераций друг от друга - условно array[i] = array[i-1] + array[i]